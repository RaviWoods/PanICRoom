{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2xwj6W_jg3Z1"
   },
   "source": [
    "### Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 4604,
     "status": "ok",
     "timestamp": 1523466575812,
     "user": {
      "displayName": "Liuqing Chen",
      "photoUrl": "//lh4.googleusercontent.com/-DtOHbAwG-nA/AAAAAAAAAAI/AAAAAAAADx8/uwmVCQwH1E4/s50-c-k-no/photo.jpg",
      "userId": "105144746069275937144"
     },
     "user_tz": -60
    },
    "id": "wLnIepl3g-XV",
    "outputId": "62aa37c4-af3b-4fe9-edee-4f9fd0777a92"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation\n",
    "from keras import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6I0lmwr2g3aC"
   },
   "source": [
    "### Download text file and clean up\n",
    "The text file downloaded is plain, we will convert it to lowercase and omit blank lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "7Iph7mSUg-Xs"
   },
   "outputs": [],
   "source": [
    "INPUT_FILE = utils.get_file(\"wonderland.txt\", \n",
    "                            origin=\"http://www.gutenberg.org/files/11/11-0.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1523466576775,
     "user": {
      "displayName": "Liuqing Chen",
      "photoUrl": "//lh4.googleusercontent.com/-DtOHbAwG-nA/AAAAAAAAAAI/AAAAAAAADx8/uwmVCQwH1E4/s50-c-k-no/photo.jpg",
      "userId": "105144746069275937144"
     },
     "user_tz": -60
    },
    "id": "1ar1GIjag-X3",
    "outputId": "ddac8be9-eef0-479f-d77b-817b29a30de7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting text from input...\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting text from input...\")\n",
    "fin = open(INPUT_FILE, 'rb')\n",
    "lines = []\n",
    "for line in fin:\n",
    "    line = line.strip().lower()\n",
    "    line = line.decode(\"ascii\", \"ignore\")\n",
    "    if len(line) == 0:  # omit blank lines\n",
    "        continue\n",
    "    lines.append(line)\n",
    "fin.close()\n",
    "text = \" \".join(lines)  # putting all lists together as a long string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C3Qrl_5gg3aM"
   },
   "source": [
    "### Creating lookup tables\n",
    "As we will do a character-based text predition, we will do some preprocessing with characters in our datasets. In order to transform characters into numbers (for training purpose), we will create a dictionary in which we can find corresponding index given a character. And vice versa, for prediction purpose, we also need to create a dictionary in which we can find corresponding character based on specific index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "atQPq1Y8g-YH"
   },
   "outputs": [],
   "source": [
    "chars = set([c for c in text])  # character vocabulary\n",
    "nb_chars = len(chars)  # total number of chars\n",
    "\n",
    "# create a dictionary for finding an index given a charcter\n",
    "char2index = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "##-----> To do: create a dictionary for finding a charcter given its index\n",
    "index2char = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-wn8PwUgg3aQ"
   },
   "source": [
    "### Prepare for inputs and outputs\n",
    " The raw inputs are fixed length strings, say SEQLEN=10\n",
    "<br> The raw outputs are the one character which follows along corresponding input string\n",
    "<br> For example, assuming an input text \"The sky was falling\", we would get the \n",
    "<br> following sequence of 'input_chars' and 'label_chars' (first 2 only)\n",
    "<br>   'The sky wa' -> 's'\n",
    "<br>   'he sky was' -> ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 369,
     "status": "ok",
     "timestamp": 1523466577969,
     "user": {
      "displayName": "Liuqing Chen",
      "photoUrl": "//lh4.googleusercontent.com/-DtOHbAwG-nA/AAAAAAAAAAI/AAAAAAAADx8/uwmVCQwH1E4/s50-c-k-no/photo.jpg",
      "userId": "105144746069275937144"
     },
     "user_tz": -60
    },
    "id": "sej4ZwWAg-YP",
    "outputId": "7b3554ec-a04c-4b03-d7e7-8dac39e60ee0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating input and label text...\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating input and label text...\")\n",
    "SEQLEN = 10\n",
    "STEP = 1\n",
    "input_chars = []\n",
    "label_chars = []\n",
    "for i in range(0, len(text) - SEQLEN, STEP):\n",
    "    input_chars.append(text[i:i + SEQLEN])\n",
    "    label_chars.append(text[i + SEQLEN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5hwZVWYXg3aU"
   },
   "source": [
    "### Vectorize inputs and outputs\n",
    " Each input string is represented by 'SEQLEN' characters\n",
    "<br> We vectorize each character as a 1-hot encoding of size len(char)/nb_chars. \n",
    "<br> So there are len(input_chars) such inputs  --> shape(X) is (len(input_chars), seqlen, nb_chars).\n",
    "<br> Similarly, we have the shape of y as (len(input_chars), nb_chars)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1523466579186,
     "user": {
      "displayName": "Liuqing Chen",
      "photoUrl": "//lh4.googleusercontent.com/-DtOHbAwG-nA/AAAAAAAAAAI/AAAAAAAADx8/uwmVCQwH1E4/s50-c-k-no/photo.jpg",
      "userId": "105144746069275937144"
     },
     "user_tz": -60
    },
    "id": "Je5OA96Tg-YX",
    "outputId": "5bd08d06-7780-4862-84fb-a3fc945a4515"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing input and label text...\n"
     ]
    }
   ],
   "source": [
    "print(\"Vectorizing input and label text...\")\n",
    "X = np.zeros((len(input_chars), SEQLEN, nb_chars), dtype=np.bool)\n",
    "y = np.zeros((len(input_chars), nb_chars), dtype=np.bool)\n",
    "for i, input_char in enumerate(input_chars):\n",
    "    for j, ch in enumerate(input_char):\n",
    "        X[i, j, char2index[ch]] = 1\n",
    "    y[i, char2index[label_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DwUmTiS0g3aa"
   },
   "source": [
    "### Build one layer LSTM model\n",
    "Here we're going to build up a one-layer LSTM model for character prediction, in which parameters will be assigned and the number of iternations and predictions will be defined as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "MAdxUBK9g-Yb"
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128  # the number of neurons in one layer LSTM\n",
    "BATCH_SIZE = 128  # the number of a batch of inputs\n",
    "NUM_ITERATIONS = 25  # the number of iterations training whole inputs datasets\n",
    "NUM_EPOCHS_PER_ITERATION = 1  # the number of epochs for one iteration\n",
    "NUM_PREDS_PER_EPOCH = 100  # the number of generated characters for one epoch\n",
    "\n",
    "model = Sequential()  # LSTM is sequential as it is a RNN type of model\n",
    "model.add(LSTM(HIDDEN_SIZE, input_shape=(SEQLEN, nb_chars)))  # add one layer of LSTM\n",
    "model.add(Dense(nb_chars))  # change the input into output shape\n",
    "model.add(Activation(\"softmax\"))  # generate probabilities\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")  # nb_chars categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EBbGqDkXrHlb"
   },
   "source": [
    "### Train and test the LSTM model\n",
    "In each iteration, we train the model first, then predict certain number of characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2587
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 920599,
     "status": "ok",
     "timestamp": 1523467500563,
     "user": {
      "displayName": "Liuqing Chen",
      "photoUrl": "//lh4.googleusercontent.com/-DtOHbAwG-nA/AAAAAAAAAAI/AAAAAAAADx8/uwmVCQwH1E4/s50-c-k-no/photo.jpg",
      "userId": "105144746069275937144"
     },
     "user_tz": -60
    },
    "id": "17EHZAQUg-Yl",
    "outputId": "40b011fe-9133-4e05-937a-ddbf3eece2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Iteration #: 0\n",
      "Epoch 1/1\n",
      "158773/158773 [==============================] - 38s 237us/step - loss: 2.4554\n",
      "Generating from seed: see what w\n",
      "see what whe she wand the said the said the said the said the said the said the said the said the said the sai\n",
      "==================================================\n",
      "Iteration #: 1\n",
      "Epoch 1/1\n",
      "  1920/158773 [..............................] - ETA: 35s - loss: 2.1750158773/158773 [==============================] - 37s 230us/step - loss: 2.0209\n",
      "Generating from seed: lectronic \n",
      "lectronic to the was the was the was the was the was the was the was the was the was the was the was the was t\n",
      "==================================================\n",
      "Iteration #: 2\n",
      "Epoch 1/1\n",
      " 36480/158773 [=====>........................] - ETA: 28s - loss: 1.8846158773/158773 [==============================] - 37s 230us/step - loss: 1.8303\n",
      "Generating from seed: jesty mean\n",
      "jesty mean the gryphon and the rather the project gutenberg-tm alice of the reat of the ray the rather the pro\n",
      "==================================================\n",
      "Iteration #: 3\n",
      "Epoch 1/1\n",
      " 43136/158773 [=======>......................] - ETA: 26s - loss: 1.7284158773/158773 [==============================] - 36s 228us/step - loss: 1.7069\n",
      "Generating from seed:  very like\n",
      " very like the gryphon a little said the gryphon a little said the gryphon a little said the gryphon a little \n",
      "==================================================\n",
      "Iteration #: 4\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.6365158773/158773 [==============================] - 36s 228us/step - loss: 1.6165\n",
      "Generating from seed: ing to dra\n",
      "ing to drast her all the said the could the said the could the said the could the said the could the said the \n",
      "==================================================\n",
      "Iteration #: 5\n",
      "Epoch 1/1\n",
      " 44928/158773 [=======>......................] - ETA: 25s - loss: 1.5578158773/158773 [==============================] - 36s 227us/step - loss: 1.5457\n",
      "Generating from seed: white rabb\n",
      "white rabbit the did a little bean the dormouse the door all the did a little bean the dormouse the door all t\n",
      "==================================================\n",
      "Iteration #: 6\n",
      "Epoch 1/1\n",
      " 44416/158773 [=======>......................] - ETA: 25s - loss: 1.4973158773/158773 [==============================] - 36s 227us/step - loss: 1.4880\n",
      "Generating from seed: e gryphon \n",
      "e gryphon a little thing the was the little thing the was the little thing the was the little thing the was th\n",
      "==================================================\n",
      "Iteration #: 7\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 26s - loss: 1.4522158773/158773 [==============================] - 36s 227us/step - loss: 1.4391\n",
      "Generating from seed: , and then\n",
      ", and then she had to herself the mock turtle say the door listle thing the mouse the mouse the mouse the mous\n",
      "==================================================\n",
      "Iteration #: 8\n",
      "Epoch 1/1\n",
      " 44928/158773 [=======>......................] - ETA: 25s - loss: 1.4073158773/158773 [==============================] - 36s 227us/step - loss: 1.3973\n",
      "Generating from seed: en a rabbi\n",
      "en a rabbit at the the project gutenberg-tm electronic works in the way so she had not to the thing as it was \n",
      "==================================================\n",
      "Iteration #: 9\n",
      "Epoch 1/1\n",
      " 44928/158773 [=======>......................] - ETA: 25s - loss: 1.3623158773/158773 [==============================] - 36s 226us/step - loss: 1.3610\n",
      "Generating from seed: peated, in\n",
      "peated, in a little share was the said to the things and the said to the things and the said to the things and\n",
      "==================================================\n",
      "Iteration #: 10\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.3231158773/158773 [==============================] - 36s 226us/step - loss: 1.3290\n",
      "Generating from seed: t assemble\n",
      "t assemble that she was the things and the mock turtle said to the things and the mock turtle said to the thin\n",
      "==================================================\n",
      "Iteration #: 11\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.2869158773/158773 [==============================] - 36s 225us/step - loss: 1.3007\n",
      "Generating from seed:  to begin \n",
      " to begin with the time the gryphon in the court, and the gryphon in the court, and the gryphon in the court, \n",
      "==================================================\n",
      "Iteration #: 12\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.2667158773/158773 [==============================] - 36s 226us/step - loss: 1.2748\n",
      "Generating from seed:  himself i\n",
      " himself in the seaged to the things and the mock turtle said to herself, and the mock turtle said to herself,\n",
      "==================================================\n",
      "Iteration #: 13\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.2470158773/158773 [==============================] - 36s 226us/step - loss: 1.2513\n",
      "Generating from seed:  grinned w\n",
      " grinned with the words was to siddly the same too said to the tree down and dont got to say the words was to \n",
      "==================================================\n",
      "Iteration #: 14\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.2199158773/158773 [==============================] - 36s 227us/step - loss: 1.2292\n",
      "Generating from seed: rpillar. w\n",
      "rpillar. what i shall in the triem to the thing as it was a little thing a little thing a little thing a littl\n",
      "==================================================\n",
      "Iteration #: 15\n",
      "Epoch 1/1\n",
      " 44160/158773 [=======>......................] - ETA: 25s - loss: 1.1978158773/158773 [==============================] - 36s 225us/step - loss: 1.2100\n",
      "Generating from seed: g mad--at \n",
      "g mad--at least in the cook the hatter. it was a little children she was not a bit all once and repeated the p\n",
      "==================================================\n",
      "Iteration #: 16\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.1776158773/158773 [==============================] - 36s 225us/step - loss: 1.1910\n",
      "Generating from seed: ice, ive o\n",
      "ice, ive or one of the lobsters and a little been the white rabbit hall the things and the mock turtle said to\n",
      "==================================================\n",
      "Iteration #: 17\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.1556158773/158773 [==============================] - 36s 225us/step - loss: 1.1726\n",
      "Generating from seed: r that mak\n",
      "r that makes the white rabbit had not a bit as she was not a bit as she was not a bit as she was not a bit as \n",
      "==================================================\n",
      "Iteration #: 18\n",
      "Epoch 1/1\n",
      " 44416/158773 [=======>......................] - ETA: 25s - loss: 1.1424158773/158773 [==============================] - 36s 225us/step - loss: 1.1558\n",
      "Generating from seed: hey need, \n",
      "hey need, said the caterpillar seemed to be no carred to herself, and she took of the works was so manner of t\n",
      "==================================================\n",
      "Iteration #: 19\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.1220158773/158773 [==============================] - 36s 225us/step - loss: 1.1406\n",
      "Generating from seed: y bowed an\n",
      "y bowed and she could show up and said to herself to say and the project gutenberg-tm electronic work is the s\n",
      "==================================================\n",
      "Iteration #: 20\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.1152158773/158773 [==============================] - 36s 225us/step - loss: 1.1255\n",
      "Generating from seed: ? said the\n",
      "? said the caterpillar. i dont know what it was a little sharp would be a little sharp would be a little sharp\n",
      "==================================================\n",
      "Iteration #: 21\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.0958158773/158773 [==============================] - 36s 225us/step - loss: 1.1111\n",
      "Generating from seed: to think, \n",
      "to think, and the same thing as i was a little bit of the court, as it said to herself, and she said to hersel\n",
      "==================================================\n",
      "Iteration #: 22\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.0835158773/158773 [==============================] - 36s 224us/step - loss: 1.0976\n",
      "Generating from seed: y uncomfor\n",
      "y uncomfortable the best of the sort of the court. what a pit of the best of the sort of the court. what a pit\n",
      "==================================================\n",
      "Iteration #: 23\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.0645158773/158773 [==============================] - 36s 224us/step - loss: 1.0847\n",
      "Generating from seed: e ornament\n",
      "e ornamented to herpelfelf, and the mock turtle said to herself, and the mock turtle said to herself, and the \n",
      "==================================================\n",
      "Iteration #: 24\n",
      "Epoch 1/1\n",
      " 44672/158773 [=======>......................] - ETA: 25s - loss: 1.0533158773/158773 [==============================] - 36s 225us/step - loss: 1.0719\n",
      "Generating from seed:  at last t\n",
      " at last the terms of this agreement sometimes to think that say a little share and all the thing whatever, an\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(NUM_ITERATIONS):\n",
    "    print(\"=\" * 50)  # separators ======\n",
    "    print(\"Iteration #: %d\" % (iteration))\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS_PER_ITERATION)  # start training\n",
    "    \n",
    "    # testing model\n",
    "    # randomly choose a row from input_chars,  \n",
    "    # then use it to generate text from model for next 100 chars\n",
    "    test_idx = np.random.randint(len(input_chars))  # randomly choose an index\n",
    "    test_chars = input_chars[test_idx]  # find the corresponding string\n",
    "    print(\"Generating from seed: %s\" % (test_chars))  # print that string\n",
    "    print(test_chars, end=\"\")  # beginning of output string \n",
    "    for i in range(NUM_PREDS_PER_EPOCH):  # print 100 characters\n",
    "        Xtest = np.zeros((1, SEQLEN, nb_chars))  # vectorize test input into one-hot embedding\n",
    "        for i, ch in enumerate(test_chars):\n",
    "            Xtest[0, i, char2index[ch]] = 1\n",
    "        pred = model.predict(Xtest, verbose=0)[0]  # predict next character with trained model\n",
    "        ##----> To do: 1) find the index which has the highest probability (refer to 'np.argmax');\n",
    "        ##----> To do: 2) and find its corresponding character (refer to 'index2char').\n",
    "        ypred = \n",
    "        print(ypred, end=\"\")\n",
    "        # move forward with 'test_chars + ypred' for next prediction\n",
    "        test_chars = test_chars[1:] + ypred  \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IhkifORK1fvX"
   },
   "source": [
    "### Questions\n",
    "- 1) Why do we need a clean up for downloaded textual file?\n",
    "- 2) Which parameters do you think have impact on the performance of the model we built?\n",
    "- 3) What do you think we can do in order to get better results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zu_Lpu5L1fvX"
   },
   "source": [
    "### Additional Exercise\n",
    "According to your answer of question 3, please try to modify above codes to improve its performance"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "LSTM_text generation_Alice_v2.1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
